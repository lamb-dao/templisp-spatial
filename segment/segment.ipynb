{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1239531a-f725-4a89-9f5d-6a649939a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geosam\n",
    "import os\n",
    "import leafmap\n",
    "from samgeo import SamGeo\n",
    "\n",
    "import torch\n",
    "\n",
    "# image conversion\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from skimage import img_as_ubyte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff618cf8-264c-4d96-8dc6-0e01405e8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map(center=[49.8653, -99.981], zoom=20, height=\"500px\")\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ca9535-eccc-47e1-9485-ed60b9ec2a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-99.9815, 49.8653, -99.9803, 49.8654]\n"
     ]
    }
   ],
   "source": [
    "# draw polygon to set m.user_roi\n",
    "\n",
    "bbox=m.user_roi_bounds()\n",
    "if bbox is None:\n",
    "    bbox = [-99.9815, 49.8653, -99.9803, 49.8654]\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a67f31-8015-4b94-835e-993d34dbf2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkwargs\\n sam_kwargs (dict, optional): Optional arguments for fine-tuning the SAM model. Defaults to None.\\n                The available arguments with default values are listed below. See https://bit.ly/410RV0v for more details.\\n\\n                points_per_side: Optional[int] = 32,\\n                points_per_batch: int = 64,\\n                pred_iou_thresh: float = 0.88,\\n                stability_score_thresh: float = 0.95,\\n                stability_score_offset: float = 1.0,\\n                box_nms_thresh: float = 0.7,\\n                crop_n_layers: int = 0,\\n                crop_nms_thresh: float = 0.7,\\n                crop_overlap_ratio: float = 512 / 1500,\\n                crop_n_points_downscale_factor: int = 1,\\n                point_grids: Optional[List[np.ndarray]] = None,\\n                min_mask_region_area: int = 0,\\n                output_mode: str = \"binary_mask\",\\n\\n        Using a SAM model, generates masks for the entire image.\\n        Generates a grid of point prompts over the image, then filters\\n        low quality and duplicate masks. The default settings are chosen\\n        for SAM with a ViT-H backbone.\\n\\n        Arguments:\\n          model (Sam): The SAM model to use for mask prediction.\\n          points_per_side (int or None): The number of points to be sampled\\n            along one side of the image. The total number of points is\\n            points_per_side**2. If None, \\'point_grids\\' must provide explicit\\n            point sampling.\\n          points_per_batch (int): Sets the number of points run simultaneously\\n            by the model. Higher numbers may be faster but use more GPU memory.\\n          pred_iou_thresh (float): A filtering threshold in [0,1], using the\\n            model\\'s predicted mask quality.\\n          stability_score_thresh (float): A filtering threshold in [0,1], using\\n            the stability of the mask under changes to the cutoff used to binarize\\n            the model\\'s mask predictions.\\n          stability_score_offset (float): The amount to shift the cutoff when\\n            calculated the stability score.\\n          box_nms_thresh (float): The box IoU cutoff used by non-maximal\\n            suppression to filter duplicate masks.\\n          crop_n_layers (int): If >0, mask prediction will be run again on\\n            crops of the image. Sets the number of layers to run, where each\\n            layer has 2**i_layer number of image crops.\\n          crop_nms_thresh (float): The box IoU cutoff used by non-maximal\\n            suppression to filter duplicate masks between different crops.\\n          crop_overlap_ratio (float): Sets the degree to which crops overlap.\\n            In the first crop layer, crops will overlap by this fraction of\\n            the image length. Later layers with more crops scale down this overlap.\\n          crop_n_points_downscale_factor (int): The number of points-per-side\\n            sampled in layer n is scaled down by crop_n_points_downscale_factor**n.\\n          point_grids (list(np.ndarray) or None): A list over explicit grids\\n            of points used for sampling, normalized to [0,1]. The nth grid in the\\n            list is used in the nth crop layer. Exclusive with points_per_side.\\n          min_mask_region_area (int): If >0, postprocessing will be applied\\n            to remove disconnected regions and holes in masks with area smaller\\n            than min_mask_region_area. Requires opencv.\\n          output_mode (str): The form masks are returned in. Can be \\'binary_mask\\',\\n            \\'uncompressed_rle\\', or \\'coco_rle\\'. \\'coco_rle\\' requires pycocotools.\\n            For large resolutions, \\'binary_mask\\' may consume large amounts of\\n            memory.\\n        '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialize sam\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "sam = SamGeo(\n",
    "    model_type='vit_b', # can be vit_h 2.4G, vit_l 1.2G, vit_b 358M\n",
    "    device=device,\n",
    "    automatic=False,\n",
    "    sam_kwargs=None,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "kwargs\n",
    " sam_kwargs (dict, optional): Optional arguments for fine-tuning the SAM model. Defaults to None.\n",
    "                The available arguments with default values are listed below. See https://bit.ly/410RV0v for more details.\n",
    "\n",
    "                points_per_side: Optional[int] = 32,\n",
    "                points_per_batch: int = 64,\n",
    "                pred_iou_thresh: float = 0.88,\n",
    "                stability_score_thresh: float = 0.95,\n",
    "                stability_score_offset: float = 1.0,\n",
    "                box_nms_thresh: float = 0.7,\n",
    "                crop_n_layers: int = 0,\n",
    "                crop_nms_thresh: float = 0.7,\n",
    "                crop_overlap_ratio: float = 512 / 1500,\n",
    "                crop_n_points_downscale_factor: int = 1,\n",
    "                point_grids: Optional[List[np.ndarray]] = None,\n",
    "                min_mask_region_area: int = 0,\n",
    "                output_mode: str = \"binary_mask\",\n",
    "\n",
    "        Using a SAM model, generates masks for the entire image.\n",
    "        Generates a grid of point prompts over the image, then filters\n",
    "        low quality and duplicate masks. The default settings are chosen\n",
    "        for SAM with a ViT-H backbone.\n",
    "\n",
    "        Arguments:\n",
    "          model (Sam): The SAM model to use for mask prediction.\n",
    "          points_per_side (int or None): The number of points to be sampled\n",
    "            along one side of the image. The total number of points is\n",
    "            points_per_side**2. If None, 'point_grids' must provide explicit\n",
    "            point sampling.\n",
    "          points_per_batch (int): Sets the number of points run simultaneously\n",
    "            by the model. Higher numbers may be faster but use more GPU memory.\n",
    "          pred_iou_thresh (float): A filtering threshold in [0,1], using the\n",
    "            model's predicted mask quality.\n",
    "          stability_score_thresh (float): A filtering threshold in [0,1], using\n",
    "            the stability of the mask under changes to the cutoff used to binarize\n",
    "            the model's mask predictions.\n",
    "          stability_score_offset (float): The amount to shift the cutoff when\n",
    "            calculated the stability score.\n",
    "          box_nms_thresh (float): The box IoU cutoff used by non-maximal\n",
    "            suppression to filter duplicate masks.\n",
    "          crop_n_layers (int): If >0, mask prediction will be run again on\n",
    "            crops of the image. Sets the number of layers to run, where each\n",
    "            layer has 2**i_layer number of image crops.\n",
    "          crop_nms_thresh (float): The box IoU cutoff used by non-maximal\n",
    "            suppression to filter duplicate masks between different crops.\n",
    "          crop_overlap_ratio (float): Sets the degree to which crops overlap.\n",
    "            In the first crop layer, crops will overlap by this fraction of\n",
    "            the image length. Later layers with more crops scale down this overlap.\n",
    "          crop_n_points_downscale_factor (int): The number of points-per-side\n",
    "            sampled in layer n is scaled down by crop_n_points_downscale_factor**n.\n",
    "          point_grids (list(np.ndarray) or None): A list over explicit grids\n",
    "            of points used for sampling, normalized to [0,1]. The nth grid in the\n",
    "            list is used in the nth crop layer. Exclusive with points_per_side.\n",
    "          min_mask_region_area (int): If >0, postprocessing will be applied\n",
    "            to remove disconnected regions and holes in masks with area smaller\n",
    "            than min_mask_region_area. Requires opencv.\n",
    "          output_mode (str): The form masks are returned in. Can be 'binary_mask',\n",
    "            'uncompressed_rle', or 'coco_rle'. 'coco_rle' requires pycocotools.\n",
    "            For large resolutions, 'binary_mask' may consume large amounts of\n",
    "            memory.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c635a8-1d1e-46f3-ac4d-1771a56fccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion function\n",
    "\n",
    "def convert_to_8bit(file_path, out_path=None):\n",
    "    \"converts 32 bit float geotiffs to 8 bit for geosam\"\n",
    "    with rasterio.open(file_path) as src:\n",
    "        img_32 = src.read()\n",
    "        metadata = src.meta\n",
    "        \n",
    "        # Normalize and convert\n",
    "        img_8 = np.zeros((3, src.height, src.width), dtype=np.uint8)\n",
    "        for band in range(3):\n",
    "            band_data = img_32[band]\n",
    "            # Normalize to [0, 1] range\n",
    "            band_norm = (band_data - band_data.min()) / (band_data.max() - band_data.min())\n",
    "            img_8[band] = img_as_ubyte(band_norm)\n",
    "\n",
    "        metadata.update({'dtype': 'uint8', \n",
    "                         'driver': 'GTiff',\n",
    "                         'nodata': 0  # Set nodata to 0 or another valid uint8 value             \n",
    "                        })\n",
    "            \n",
    "\n",
    "        if out_path is None:\n",
    "            base, ext = os.path.splitext(file_path)\n",
    "            out_path = f\"{base}_8bit{ext}\"\n",
    "         \n",
    "        if os.path.exists(out_path):\n",
    "            os.remove(out_path)\n",
    "        \n",
    "        with rasterio.open(out_path, 'w', **metadata) as dst:\n",
    "           dst.write(img_8)\n",
    "        \n",
    "        return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c6bd9e-aa0c-4092-b2ed-560dbed7d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image selection function\n",
    "def select_image(image):\n",
    "    # display selected image\n",
    "    m.layers[-1].visible = False\n",
    "    m.add_raster(image, layer_name=\"Image\")\n",
    "\n",
    "    # set the image to segment\n",
    "    sam.set_image(image)\n",
    "    print(f\"set image: {image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc21636-04f6-4f0f-87bb-0acd72df05c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 10\n"
     ]
    }
   ],
   "source": [
    "# set images\n",
    "image1_32bit = '/home/user/qgis/bgr-composites/2023-07-04_bgr.tif'\n",
    "image2_32bit = '/home/user/qgis/bgr-composites/2023-07-11_bgr.tif'\n",
    "image3_32bit = '/home/user/qgis/bgr-composites/2023-07-17_bgr.tif'\n",
    "image4_32bit = '/home/user/qgis/bgr-composites/2023-07-24_bgr.tif'\n",
    "image5_32bit = '/home/user/qgis/bgr-composites/2023-07-31_bgr.tif'\n",
    "image6_32bit = '/home/user/qgis/bgr-composites/2023-08-02_bgr.tif'\n",
    "image7_32bit = '/home/user/qgis/bgr-composites/2023-08-08_bgr.tif'\n",
    "image8_32bit = '/home/user/qgis/bgr-composites/2023-08-14_bgr.tif'\n",
    "image9_32bit = '/home/user/qgis/bgr-composites/2023-08-29_bgr.tif'\n",
    "image10_32bit = '/home/user/qgis/bgr-composites/2023-09-05_bgr.tif'\n",
    "\n",
    "\n",
    "\n",
    "# convert images\n",
    "image1 = convert_to_8bit(image1_32bit) \n",
    "image2 = convert_to_8bit(image2_32bit) \n",
    "image3 = convert_to_8bit(image3_32bit) \n",
    "image4 = convert_to_8bit(image4_32bit) \n",
    "image5 = convert_to_8bit(image5_32bit) \n",
    "image6 = convert_to_8bit(image6_32bit) \n",
    "image7 = convert_to_8bit(image7_32bit) \n",
    "image8 = convert_to_8bit(image8_32bit) \n",
    "image9 = convert_to_8bit(image9_32bit) \n",
    "image10 = convert_to_8bit(image10_32bit) \n",
    "\n",
    "print(\"set 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae6f4c8e-1cd1-44f2-a051-5fa1b415b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set image: /home/user/qgis/bgr-composites/2023-07-17_bgr_8bit.tif\n"
     ]
    }
   ],
   "source": [
    "select_image(image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "721a6257-9d1c-4882-acbf-33ffb9ad800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d435b41c61de4a718ea1d448d2db6ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[49.865300000000005, -99.9809], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_inâ€¦"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sam.show_map()\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50945f35-b5d6-49c1-9a42-354dc2a76186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid pixel coordinates found.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m point_coords \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m122.1419\u001b[39m, \u001b[38;5;241m37.6383\u001b[39m]]\n\u001b[0;32m----> 2\u001b[0m \u001b[43msam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint_crs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEPSG:32614\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask1.tif\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m m\u001b[38;5;241m.\u001b[39madd_raster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask1.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, layer_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask1\u001b[39m\u001b[38;5;124m\"\u001b[39m, nodata\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m, opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m m\n",
      "File \u001b[0;32m~/.conda/envs/geo/lib/python3.13/site-packages/samgeo/hq_sam.py:587\u001b[0m, in \u001b[0;36mSamGeo.predict\u001b[0;34m(self, point_coords, point_labels, boxes, point_crs, mask_input, multimask_output, return_logits, output, index, mask_multiplier, dtype, return_results, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(boxes, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(boxes[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    586\u001b[0m         boxes \u001b[38;5;241m=\u001b[39m boxes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 587\u001b[0m     masks, scores, logits \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoint_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoint_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultimask_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m     masks, scores, logits \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict_torch(\n\u001b[1;32m    597\u001b[0m         point_coords\u001b[38;5;241m=\u001b[39mpoint_coords,\n\u001b[1;32m    598\u001b[0m         point_labels\u001b[38;5;241m=\u001b[39mpoint_coords,\n\u001b[1;32m    599\u001b[0m         boxes\u001b[38;5;241m=\u001b[39minput_boxes,\n\u001b[1;32m    600\u001b[0m         multimask_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    601\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/geo/lib/python3.13/site-packages/segment_anything_hq/predictor.py:145\u001b[0m, in \u001b[0;36mSamPredictor.predict\u001b[0;34m(self, point_coords, point_labels, box, mask_input, multimask_output, return_logits, hq_token_only)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m point_coords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    143\u001b[0m         point_labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoint_labels must be supplied if point_coords is supplied.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 145\u001b[0m     point_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     coords_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(point_coords, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    147\u001b[0m     labels_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(point_labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.conda/envs/geo/lib/python3.13/site-packages/segment_anything_hq/utils/transforms.py:43\u001b[0m, in \u001b[0;36mResizeLongestSide.apply_coords\u001b[0;34m(self, coords, original_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m new_h, new_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_preprocess_shape(\n\u001b[1;32m     40\u001b[0m     original_size[\u001b[38;5;241m0\u001b[39m], original_size[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_length\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m coords \u001b[38;5;241m=\u001b[39m deepcopy(coords)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m coords[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcoords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m (new_w \u001b[38;5;241m/\u001b[39m old_w)\n\u001b[1;32m     44\u001b[0m coords[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m coords[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (new_h \u001b[38;5;241m/\u001b[39m old_h)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coords\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "point_coords = [[-122.1419, 37.6383]]\n",
    "sam.predict(point_coords, point_labels=1, point_crs=\"EPSG:32614\", output=\"mask1.tif\")\n",
    "m.add_raster(\"mask1.tif\", layer_name=\"Mask1\", nodata=0, cmap=\"Blues\", opacity=1)\n",
    "m\n",
    "\n",
    "point_coords = [[-122.1464, 37.6431], [-122.1449, 37.6415], [-122.1451, 37.6395]]\n",
    "sam.predict(point_coords, point_labels=1, point_crs=\"EPSG:32614\", output=\"mask2.tif\")\n",
    "m.add_raster(\"mask2.tif\", layer_name=\"Mask2\", nodata=0, cmap=\"Greens\", opacity=1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768898a-95bb-44d8-a91b-5bca80ba40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# &&& segment with scripted negative points\n",
    "sam.predict(point_coords, point_labels=1, point_crs=\"EPSG:32614\", output=\"mask1.tif\")\n",
    "point_labels, 1 fg 0 bg\n",
    "# &&& show points function, []to map\n",
    "# &&& print current points function, map to []\n",
    "# &&& show mask function\n",
    "# &&& makseg function, args: maskName layerName points opt show points show mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
